#!/usr/bin/env python3
"""
è´¹ç‡æ–¹æ¡ˆæå–è„šæœ¬ v2.1
ä»é™„åŠ é™©è´¹ç‡æ–¹æ¡ˆ docx/doc æ–‡ä»¶ä¸­æå–ç»“æ„åŒ–æ•°æ®ï¼Œè¾“å‡º JSONã€‚
æ”¯æŒé›‡ä¸»è´£ä»»ä¿é™©ã€ä¼ä¸šè´¢äº§ä¿é™©ç­‰å¤šè¡Œä¸šé™„åŠ æ¡æ¬¾ã€‚

ç”¨æ³•:
    python3 extract_rates.py "/path/to/é™„åŠ é™©åŠè´¹ç‡" -o rate_data.json

è´¹ç‡æ–¹æ¡ˆåˆ†ç±»ï¼ˆä¸ HTML ç«¯ä¸€è‡´ï¼‰:
  - simple_percentage: ä¸»é™©ä¿è´¹çš„å›ºå®šåŠ æ”¶ç™¾åˆ†æ¯”
  - deduction: å‡æ”¶ä¸»é™©ä¿è´¹çš„ç™¾åˆ†æ¯”
  - modifier_coeff: è°ƒæ•´ç³»æ•°ï¼ˆå¦‚è¯¯å·¥è´¹ï¼‰
  - sudden_death: çªå‘ç–¾ç—…èº«æ•…ç±»ï¼ˆåŸºå‡†è´¹ç‡Ã—é™é¢Ã—äººæ•°ï¼‰
  - per_person_rate: æ¯äººè´¹ç‡ï¼ˆåŒºåˆ†å·¥ä¼¤ä¿é™©çŠ¶æ€ï¼‰
  - per_person_base: æ¯äººå®šé¢ï¼ˆå¦‚è¯å“æœåŠ¡ï¼‰
  - disability_adjust: ä¼¤æ®‹èµ”å¿æ¯”ä¾‹è°ƒæ•´
  - property_loss: è´¢äº§æŸå¤±ï¼ˆåŸºæœ¬ä¿é™©è´¹+é™é¢Ã—è´¹ç‡ï¼‰
  - formula_sum: æ±‚å’Œå…¬å¼ï¼ˆé›‡ä¸»æ³•å¾‹è´£ä»»/ä¸€æ¬¡æ€§ä¼¤æ®‹ï¼‰
  - table_coefficient: å¤šç³»æ•°è¡¨ç›¸ä¹˜
  - no_calc: æœ‰è®¡è´¹è¯´æ˜ä½†æ— éœ€å•ç‹¬è®¡ç®—
  - regulatory: ä¸æ¶‰åŠè´¹ç”¨è°ƒæ•´
  - included_in_main: çº³å…¥ä¸»é™©ä¿é™©é‡‘é¢è®¡æ”¶ä¿é™©è´¹
  - daily_prorate: æŒ‰æ—¥æ¯”ä¾‹è®¡ç®—ä¿è´¹
"""

import argparse
import json
import os
import re
import sys
from datetime import datetime

try:
    from docx import Document
except ImportError:
    print("éœ€è¦å®‰è£… python-docx: pip3 install python-docx")
    sys.exit(1)


# ---------------------------------------------------------------------------
# å™ªéŸ³è¿‡æ»¤
# ---------------------------------------------------------------------------
NOISE_PATTERNS = [
    re.compile(r'PAGE\s+', re.IGNORECASE),
    re.compile(r'NUMPAGES', re.IGNORECASE),
    re.compile(r'MERGEFORMAT', re.IGNORECASE),
    re.compile(r'ç¬¬\s*.*é¡µ\s*å…±\s*.*é¡µ'),
    re.compile(r'^-\s*\d+\s*-$'),
    re.compile(r'^\d+$'),
]

COMPANY_PREFIX = "ä¸­å›½å¤ªå¹³æ´‹è´¢äº§ä¿é™©è‚¡ä»½æœ‰é™å…¬å¸"


def is_noise(text):
    """åˆ¤æ–­æ®µè½æ˜¯å¦ä¸ºå™ªéŸ³è¡Œã€‚"""
    stripped = text.strip()
    if not stripped:
        return True
    for pat in NOISE_PATTERNS:
        if pat.search(stripped):
            return True
    return False


def clean_paragraphs(doc):
    """æå–å¹¶æ¸…ç†æ–‡æ¡£æ®µè½æ–‡æœ¬ã€‚"""
    result = []
    for p in doc.paragraphs:
        text = p.text.strip()
        if text and not is_noise(text):
            result.append(text)
    return result


# ---------------------------------------------------------------------------
# è¡¨æ ¼è§£æ
# ---------------------------------------------------------------------------
def parse_tables(doc):
    """æå–æ–‡æ¡£ä¸­çš„æ‰€æœ‰è¡¨æ ¼ä¸º list[list[list[str]]]ã€‚"""
    tables = []
    for table in doc.tables:
        rows = []
        for row in table.rows:
            cells = [cell.text.strip().replace('\n', ' ') for cell in row.cells]
            rows.append(cells)
        if rows:
            tables.append(rows)
    return tables


def parse_coefficient_value(text):
    """è§£æç³»æ•°å€¼æ–‡æœ¬ï¼Œè¿”å›ç»“æ„åŒ–æ•°æ®ã€‚"""
    text = text.strip()
    # æ›¿æ¢å…¨è§’å­—ç¬¦
    text = text.replace('ï¼Œ', ',').replace('ï¼ˆ', '(').replace('ï¼‰', ')')

    # èŒƒå›´æ ¼å¼: [0.7, 0.8] æˆ– (0.7, 0.8] ç­‰
    range_match = re.match(
        r'[\[(\ï¼ˆ\[]?\s*([\d.]+)\s*[,ï¼Œ]\s*([\d.]+)\s*[\])\ï¼‰\]]?', text
    )
    if range_match:
        lo = float(range_match.group(1))
        hi = float(range_match.group(2))
        return {"type": "range", "min": lo, "max": hi, "display": text}

    # å›ºå®šæ•°å€¼
    num_match = re.match(r'^([\d.]+)$', text)
    if num_match:
        return {"type": "fixed", "value": float(num_match.group(1)), "display": text}

    # å…¶ä»–æ–‡æœ¬
    return {"type": "text", "display": text}


def build_coefficient_table(raw_table, paragraphs):
    """ä»åŸå§‹è¡¨æ ¼æ•°æ®æ„å»ºç³»æ•°è¡¨ç»“æ„ã€‚"""
    if len(raw_table) < 2:
        return None

    header = raw_table[0]
    table_name = header[0] if header[0] else "è°ƒæ•´ç³»æ•°"

    # æ£€æµ‹æ˜¯å¦æ”¯æŒçº¿æ€§æ’å€¼
    supports_interpolation = any(
        'çº¿æ€§æ’å€¼' in p or 'æ’å€¼' in p for p in paragraphs
    )

    rows = []
    for row_data in raw_table[1:]:
        if len(row_data) < 2:
            continue
        param = row_data[0].strip()
        coeff_text = row_data[1].strip()
        if not param or not coeff_text:
            continue
        parsed = parse_coefficient_value(coeff_text)
        rows.append({
            "parameter": param,
            "coefficient": coeff_text,
            "parsedValue": parsed
        })

    if not rows:
        return None

    return {
        "name": table_name,
        "headerRow": header,
        "supportsInterpolation": supports_interpolation,
        "rows": rows
    }


# ---------------------------------------------------------------------------
# è´¹ç‡ç±»å‹åˆ†ç±»
# ---------------------------------------------------------------------------
def extract_percentage(text):
    """ä»æ–‡æœ¬ä¸­æå–ç™¾åˆ†æ¯”æ•°å€¼ã€‚"""
    # åŒ¹é… "5%" æˆ– "5ï¼…" æˆ– "ç™¾åˆ†ä¹‹äº”"
    m = re.search(r'([\d.]+)\s*[%ï¼…]', text)
    if m:
        return float(m.group(1))
    return None


def extract_multiplier(text):
    """ä»æ–‡æœ¬ä¸­æå–å€æ•°ã€‚"""
    m = re.search(r'ä¸»é™©ä¿é™©è´¹çš„\s*([\d.]+)\s*å€', text)
    if m:
        return float(m.group(1))
    return None


def classify_and_extract(paragraphs, tables, filename):
    """æ ¹æ®æ®µè½å’Œè¡¨æ ¼å†…å®¹åˆ†ç±»è´¹ç‡ç±»å‹å¹¶æå–æ•°æ®ï¼ˆv2.0ï¼Œä¸ HTML ç«¯ä¸€è‡´ï¼‰ã€‚"""
    full_text = ' '.join(paragraphs)

    # è¿‡æ»¤æ‰å…¬å¸åå’Œæ ‡é¢˜è¡Œï¼Œè·å–å®è´¨æ®µè½
    substantive = [
        p for p in paragraphs
        if COMPANY_PREFIX not in p
        and not (p.endswith('è´¹ç‡æ–¹æ¡ˆ') and len(p) < 100)
    ]

    # ä»æ–‡ä»¶åä¸­æå–æ¡æ¬¾ç®€ç§°
    clause_name = filename.replace('.docx', '').replace('.doc', '')
    clause_name = clause_name.replace(COMPANY_PREFIX, '')

    # ---- regulatory ----
    regulatory_keywords = [
        'ä¸æ¶‰åŠä¿é™©è´¹çš„è°ƒæ•´',
        'å±äºè§„èŒƒç±»',
        'ä¸æ¶‰åŠè´¹ç‡',
        'ä¸å¦æ”¶ä¿é™©è´¹',
        'ä¸å¢å‡ä¸»é™©çš„ä¿é™©è´¹',
        'ä¸å¢å‡ä¸»é™©ä¿é™©è´¹',
    ]
    is_purely_regulatory = (
        not tables
        and substantive
        and all(
            any(kw in p for kw in regulatory_keywords)
            or 'ä¿å•æœ€ç»ˆä¿é™©è´¹' in p
            or 'å·¥èµ„æ€»é¢' in p
            for p in substantive
        )
    )
    if is_purely_regulatory:
        return {
            "rateType": "regulatory",
            "description": substantive[0][:300] if substantive else ""
        }

    # ---- æ„å»ºç³»æ•°è¡¨ ----
    coeff_tables = []
    if tables:
        for raw_table in tables:
            ct = build_coefficient_table(raw_table, paragraphs)
            if ct:
                coeff_tables.append(ct)

    # ---- æå–ç™¾åˆ†æ¯” ----
    percentages = []
    for p in paragraphs:
        for m in re.finditer(r'([\d.]+)\s*[%ï¼…]', p):
            percentages.append({"value": float(m.group(1)), "context": p})

    # ---- å…³é”®è¯æ£€æµ‹è´¹ç‡ç±»å‹ï¼ˆä¸ HTML ç«¯ RC_ADDON_KEYWORD_MAP ä¸€è‡´ï¼‰----
    keyword_map = [
        (['è¯¯å·¥è´¹'], 'modifier_coeff'),
        (['çªå‘ç–¾ç—…èº«æ•…'], 'sudden_death'),
        (['å·¥ä¼¤è¡¥å……', 'ç‰¹å®šäººå‘˜'], 'per_person_rate'),
        (['è¯å“æœåŠ¡', 'è¯å“è´¹ç”¨'], 'per_person_base'),
        (['åŠ³åŠ¡å…³ç³»äººå‘˜'], 'disability_adjust'),
        (['ç‰¹å®šè´¢äº§æŸå¤±'], 'property_loss'),
        (['é›‡ä¸»æ³•å¾‹è´£ä»»', 'æ³•å¾‹è´¹ç”¨è´£ä»»'], 'formula_sum'),
        (['ä¸€æ¬¡æ€§ä¼¤æ®‹'], 'formula_sum'),
        (['çªå‘ç–¾ç—…é™¤å¤–', 'çŒæ­»é™¤å¤–'], 'deduction'),
        (['æœˆç”³æŠ¥', 'å‘˜å·¥è‡ªåŠ¨æ‰¿ä¿', 'æ¯æœˆç”³æŠ¥'], 'no_calc'),
    ]

    detected_type = None
    for keywords, rate_type in keyword_map:
        if any(kw in clause_name for kw in keywords):
            detected_type = rate_type
            break

    # ---- æŒ‰æ£€æµ‹ç±»å‹æ„å»º entry ----

    if detected_type == 'modifier_coeff':
        return {
            "rateType": "modifier_coeff",
            "coefficientTables": coeff_tables,
            "description": substantive[0] if substantive else "",
            "formula": "è°ƒæ•´åä¸»é™©ä¿è´¹ = ä¸»é™©ä¿è´¹ Ã— å…èµ”å¤©æ•°è°ƒæ•´ç³»æ•°"
        }

    if detected_type == 'sudden_death':
        base_pct = 6.6
        for pi in percentages:
            if 'åŸºå‡†ä¿é™©è´¹' in pi["context"] or 'æ¯äººæ¯æ¬¡äº‹æ•…èµ”å¿é™é¢' in pi["context"]:
                base_pct = pi["value"]
                break
        return {
            "rateType": "sudden_death",
            "basePercent": base_pct,
            "coefficientTables": coeff_tables,
            "description": substantive[0] if substantive else "",
            "formula": f"åŸºå‡†ä¿è´¹ = æ¯äººé™é¢ Ã— {base_pct}% Ã— äººæ•°ï¼Œå†ä¹˜ä»¥ç³»æ•°è°ƒæ•´"
        }

    if detected_type == 'per_person_rate':
        rate_info = {}
        for pi in percentages:
            ctx = pi["context"]
            if 'å·²è´­ä¹°å·¥ä¼¤ä¿é™©' in ctx or 'æœ‰å·¥ä¼¤' in ctx:
                rate_info["with_injury_insurance"] = pi["value"]
            elif 'æœªè´­ä¹°å·¥ä¼¤ä¿é™©' in ctx or 'æ— å·¥ä¼¤' in ctx:
                rate_info["without_injury_insurance"] = pi["value"]
            elif "default" not in rate_info:
                rate_info["default"] = pi["value"]
        return {
            "rateType": "per_person_rate",
            "rateInfo": rate_info,
            "coefficientTables": coeff_tables,
            "description": substantive[0] if substantive else "",
            "formula": "ä¿è´¹ = æ¯äººä¿è´¹ Ã— è´¹ç‡% Ã— äººæ•° Ã— ç³»æ•°"
        }

    if detected_type == 'per_person_base':
        base_amount = 300
        for p in paragraphs:
            amt_m = re.search(r'(\d+)\s*å…ƒ[/ï¼æ¯]äºº', p)
            if amt_m:
                base_amount = int(amt_m.group(1))
                break
        return {
            "rateType": "per_person_base",
            "baseAmount": base_amount,
            "coefficientTables": coeff_tables,
            "description": substantive[0] if substantive else "",
            "formula": f"ä¿è´¹ = {base_amount}å…ƒ/äºº Ã— ç³»æ•° Ã— äººæ•°"
        }

    if detected_type == 'disability_adjust':
        return {
            "rateType": "disability_adjust",
            "adjustCoeffs": {"table1": 0.995, "table2": 1.072, "table3": 0.919},
            "description": substantive[0] if substantive else "",
            "formula": "ä¿è´¹ = æ¯äººä¿è´¹ Ã— ä¼¤æ®‹è°ƒæ•´ç³»æ•° Ã— äººæ•°"
        }

    if detected_type == 'property_loss':
        base_premium = 20
        base_rate_pct = 1.5
        for pi in percentages:
            base_rate_pct = pi["value"]
            break
        for p in paragraphs:
            amt_m = re.search(r'åŸº[æœ¬å‡†]ä¿é™©è´¹[=ï¼]?\s*(\d+)\s*å…ƒ', p)
            if amt_m:
                base_premium = int(amt_m.group(1))
                break
        return {
            "rateType": "property_loss",
            "basePremium": base_premium,
            "baseRatePercent": base_rate_pct,
            "coefficientTables": coeff_tables,
            "description": substantive[0] if substantive else "",
            "formula": f"ä¿è´¹ = ({base_premium}å…ƒ + æ¯äººèµ”å¿é™é¢ Ã— {base_rate_pct}%) Ã— ç³»æ•°ç§¯ Ã— æ‰¿ä¿äººæ•°"
        }

    if detected_type == 'formula_sum':
        base_rate_factor = 1.0
        if 'ä¸€æ¬¡æ€§ä¼¤æ®‹' in clause_name:
            if 'Aæ¬¾' in clause_name or 'ï¼ˆAï¼‰' in clause_name:
                base_rate_factor = 0.9
            elif 'Bæ¬¾' in clause_name or 'ï¼ˆBï¼‰' in clause_name:
                base_rate_factor = 1.0
            elif 'Cæ¬¾' in clause_name or 'ï¼ˆCï¼‰' in clause_name:
                base_rate_factor = 1.1
            elif 'Dæ¬¾' in clause_name or 'ï¼ˆDï¼‰' in clause_name:
                base_rate_factor = 1.2
        else:
            if '90' in full_text:
                base_rate_factor = 0.9
            elif '95' in full_text:
                base_rate_factor = 0.95
        return {
            "rateType": "formula_sum",
            "baseRateFactor": base_rate_factor,
            "coefficientTables": coeff_tables,
            "description": substantive[0] if substantive else "",
            "formula": f"ä¿è´¹ = Î£(æ¯äººé™é¢ Ã— ä¸»é™©åŸºå‡†è´¹ç‡ Ã— {base_rate_factor} Ã— äººæ•° Ã— ç³»æ•°ç§¯)"
        }

    if detected_type == 'deduction':
        deduct_pct = 5.0
        if percentages:
            deduct_pct = percentages[0]["value"]
        return {
            "rateType": "deduction",
            "deductPercent": deduct_pct,
            "description": substantive[0] if substantive else "",
            "formula": f"å‡æ”¶ = ä¸»é™©ä¿è´¹ Ã— {deduct_pct}%"
        }

    if detected_type == 'no_calc':
        return {
            "rateType": "no_calc",
            "description": substantive[0] if substantive else full_text[:300],
            "formula": "æœ¬æ¡æ¬¾æœ‰è®¡è´¹è¯´æ˜ä½†æ— éœ€å•ç‹¬è®¡ç®—é™„åŠ ä¿è´¹"
        }

    # ---- æ–°ç±»å‹: included_in_mainï¼ˆçº³å…¥ä¸»é™©ä¿é™©é‡‘é¢ï¼‰----
    included_keywords = ['çº³å…¥ä¸»é™©ä¿é™©é‡‘é¢è®¡æ”¶ä¿é™©è´¹', 'çº³å…¥ä¸»é™©ä¿é™©é‡‘é¢', 'åº”çº³å…¥ä¸»é™©ä¿é™©é‡‘é¢']
    if any(kw in full_text for kw in included_keywords) and not tables:
        return {
            "rateType": "included_in_main",
            "description": next(
                (p for p in substantive if any(kw in p for kw in included_keywords)),
                ""
            ),
            "formula": "çº³å…¥ä¸»é™©ä¿é™©é‡‘é¢ï¼ŒæŒ‰ä¸»é™©è´¹ç‡è®¡æ”¶ä¿é™©è´¹ï¼Œä¸å¦æ”¶é™„åŠ ä¿é™©è´¹"
        }

    # ---- æ–°ç±»å‹: daily_prorateï¼ˆæŒ‰æ—¥æ¯”ä¾‹è®¡ç®—ï¼‰----
    daily_keywords = ['æŒ‰æ—¥æ¯”ä¾‹è®¡ç®—', 'æŒ‰æ—¥æ¯”ä¾‹æ”¶å–', 'ä»å‘ç”ŸæŸå¤±ä¹‹æ—¥èµ·è‡³ä¿é™©æ­¢æœŸæŒ‰æ—¥æ¯”ä¾‹']
    if any(kw in full_text for kw in daily_keywords):
        formula_text = next(
            (p for p in paragraphs if any(kw in p for kw in daily_keywords)),
            ""
        )
        return {
            "rateType": "daily_prorate",
            "description": formula_text[:300],
            "formula": "æŒ‰æ—¥æ¯”ä¾‹è®¡ç®—ä¿è´¹ = ä¿é™©é‡‘é¢ Ã— ä¿å•è´¹ç‡ Ã— (å¤©æ•° / 365)"
        }

    # ---- æœªåŒ¹é…å…³é”®è¯ï¼Œèµ°é€šç”¨æ£€æµ‹ ----

    # table_coefficient
    if coeff_tables:
        base_premium = _extract_base_premium(paragraphs)
        formula = _extract_formula(paragraphs)
        result = {
            "rateType": "table_coefficient",
            "basePremium": base_premium,
            "coefficientTables": coeff_tables,
            "formula": formula,
            "description": _find_description(paragraphs)
        }
        extra_rules = _extract_extra_rules(paragraphs)
        if extra_rules:
            result["extraRules"] = extra_rules
        return result

    # æ£€æµ‹å‡æ”¶/å‡å°‘ç±»ï¼ˆdeductionï¼‰
    for p in substantive:
        if ('å‡å°‘' in p or 'å‡æ”¶' in p) and extract_percentage(p) is not None:
            pct = extract_percentage(p)
            return {
                "rateType": "deduction",
                "deductPercent": pct,
                "description": p,
                "formula": f"å‡æ”¶ = ä¸»é™©ä¿è´¹ Ã— {pct}%"
            }

    # formula_conditional
    has_formula_sign = any('ï¼' in p or 'Ã—' in p for p in substantive)
    has_condition = any(
        any(kw in p for kw in ['è‹¥', 'å¦‚æœ'])
        for p in substantive
    )

    if has_condition or (has_formula_sign and not tables):
        conditions = _extract_conditions(paragraphs)
        base_rate = None
        for p in paragraphs:
            pct = extract_percentage(p)
            if pct:
                base_rate = pct
                break
        return {
            "rateType": "formula_conditional",
            "baseRatePercent": base_rate,
            "conditions": conditions,
            "description": _find_description(paragraphs)
        }

    # simple_percentage
    for p in paragraphs:
        pct = extract_percentage(p)
        if pct is not None:
            return {
                "rateType": "simple_percentage",
                "percentage": pct,
                "description": p
            }

    # å€æ•°å½¢å¼
    for p in paragraphs:
        mult = extract_multiplier(p)
        if mult is not None:
            return {
                "rateType": "simple_percentage",
                "percentage": mult * 100,
                "multiplier": mult,
                "description": p
            }

    # regulatory fallback
    adjustment_keywords = ['ä¿å•æœ€ç»ˆä¿é™©è´¹', 'å·¥èµ„æ€»é¢è¿›è¡Œè°ƒæ•´', 'ä¿è´¹è°ƒæ•´', 'æŒ‰ä¿é™©è´¹ç‡è¡¥ç¼´ä¿é™©è´¹']
    for kw in adjustment_keywords:
        if kw in full_text:
            return {
                "rateType": "regulatory",
                "description": next(
                    (p for p in paragraphs if kw in p or 'è°ƒæ•´' in p),
                    full_text[:200]
                )
            }

    # fallback
    return {
        "rateType": "unknown",
        "description": full_text[:300] if full_text else "æ— æ³•è¯†åˆ«è´¹ç‡ç±»å‹"
    }


def _extract_base_premium(paragraphs):
    """æå–åŸºå‡†ä¿é™©è´¹æè¿°ã€‚"""
    for p in paragraphs:
        if 'åŸºå‡†ä¿é™©è´¹' in p or 'åŸºå‡†ä¿è´¹' in p:
            pct = extract_percentage(p)
            mult = extract_multiplier(p)
            # ä¼˜å…ˆåŒ¹é… "ä¸»é™©ä¿é™©è´¹çš„X%" æ ¼å¼ï¼ˆä¼ä¸šè´¢äº§é™©å¸¸è§ï¼‰
            m = re.search(r'ä¸»é™©ä¿é™©è´¹çš„\s*([\d.]+)\s*[%ï¼…]', p)
            if m:
                return {
                    "description": p,
                    "percentage": float(m.group(1))
                }
            result = {"description": p}
            if pct:
                result["percentage"] = pct
            if mult:
                result["multiplier"] = mult
            return result
    # å›é€€: æŸ¥æ‰¾ "ä¸»é™©ä¿é™©è´¹çš„X%"
    for p in paragraphs:
        m = re.search(r'ä¸»é™©ä¿é™©è´¹çš„\s*([\d.]+)\s*[%ï¼…]', p)
        if m:
            return {
                "description": p,
                "percentage": float(m.group(1))
            }
        m2 = re.search(r'ä¸»é™©ä¿é™©è´¹çš„\s*([\d.]+)\s*å€', p)
        if m2:
            return {
                "description": p,
                "multiplier": float(m2.group(1))
            }
    return {"description": "æœªæ‰¾åˆ°åŸºå‡†ä¿é™©è´¹æè¿°"}


def _extract_formula(paragraphs):
    """æå–è®¡ç®—å…¬å¼ã€‚"""
    for p in paragraphs:
        if 'ä¿é™©è´¹' in p and ('Ã—' in p or 'ï¼' in p or 'ä¹˜ç§¯' in p):
            return p
    return "ä¿é™©è´¹ = åŸºå‡†ä¿é™©è´¹ Ã— å„é¡¹è´¹ç‡è°ƒæ•´ç³»æ•°çš„ä¹˜ç§¯"


def _extract_conditions(paragraphs):
    """æå–æ¡ä»¶å…¬å¼åˆ—è¡¨ã€‚"""
    conditions = []
    for p in paragraphs:
        if any(kw in p for kw in ['è‹¥', 'å¦‚æœ']) and (
            'ï¼' in p or 'Ã—' in p or '%' in p or 'ï¼…' in p or
            'å‡æ”¶' in p or 'åŠ æ”¶' in p or 'å‡å°‘' in p or
            'ä¸è°ƒæ•´' in p or 'ä¸æ¶‰åŠ' in p
        ):
            # æå–æ¡ä»¶éƒ¨åˆ†å’Œå…¬å¼éƒ¨åˆ†
            condition_part = p
            formula_part = p
            # å°è¯•æŒ‰é€—å·åˆ†å‰²
            for sep in ['ï¼Œ', ',', 'ï¼š', ':']:
                if sep in p:
                    parts = p.split(sep, 1)
                    if len(parts) == 2:
                        condition_part = parts[0].strip()
                        formula_part = parts[1].strip()
                    break
            conditions.append({
                "condition": condition_part,
                "formula": formula_part,
                "fullText": p
            })
        elif 'ä¸æ¶‰åŠä¿é™©è´¹çš„è°ƒæ•´' in p or 'åˆ™ä¸æ¶‰åŠ' in p or 'åˆ™ä¸è°ƒæ•´ä¿é™©è´¹' in p:
            conditions.append({
                "condition": p,
                "formula": "ä¸è°ƒæ•´",
                "fullText": p
            })
        # ä¼ä¸šè´¢äº§é™©: "å¢åŠ çš„ä¿é™©è´¹ï¼Î£ï¼ˆä¿é™©é‡‘é¢Ã—è´¹ç‡Ã—å¤©æ•°/365ï¼‰" æ¨¡å¼
        elif ('Î£' in p or 'âˆ‘' in p or 'æ±‚å’Œ' in p) and ('Ã—' in p or 'ï¼' in p):
            conditions.append({
                "condition": "æ±‚å’Œå…¬å¼",
                "formula": p,
                "fullText": p
            })
    return conditions


def _extract_extra_rules(paragraphs):
    """æå–é™„åŠ è§„åˆ™ï¼ˆå¦‚æœªè´­ä¹°å·¥ä¼¤ä¿é™©ç­‰æ¡ä»¶ï¼‰ã€‚"""
    rules = []
    for p in paragraphs:
        if 'æœªè´­ä¹°' in p or 'æœªå‚åŠ ' in p or 'æœªæŠ•ä¿' in p:
            rules.append(p)
    return rules if rules else None


def _find_description(paragraphs):
    """è·å–è´¹ç‡æ–¹æ¡ˆçš„ç®€è¦æè¿°ã€‚"""
    # è·³è¿‡å…¬å¸åå’Œæ ‡é¢˜,å–ç¬¬ä¸€ä¸ªå®è´¨æ®µè½
    for p in paragraphs:
        if COMPANY_PREFIX in p:
            continue
        if 'è´¹ç‡æ–¹æ¡ˆ' in p and len(p) < 80:
            continue
        if p.strip():
            return p[:300]
    return ""


# ---------------------------------------------------------------------------
# æ–‡ä»¶åè§£æ
# ---------------------------------------------------------------------------
def parse_filename(filename):
    """ä»æ–‡ä»¶åä¸­æå–æ¡æ¬¾åç§°å’Œè¡Œä¸šä¿¡æ¯ã€‚"""
    name = filename.replace('.docx', '').replace('.doc', '')

    # å»æ‰å…¬å¸å‰ç¼€
    name = name.replace(COMPANY_PREFIX, '')

    # æå–è¡Œä¸šä¿¡æ¯
    industry = "é›‡ä¸»è´£ä»»ä¿é™©"
    industry_patterns = [
        (r'ä¼ä¸šè´¢äº§ä¿é™©', 'ä¼ä¸šè´¢äº§ä¿é™©'),
        (r'å››å·çœå»ºç­‘æ–½å·¥ä¼ä¸š', 'å››å·çœå»ºç­‘æ–½å·¥ä¼ä¸šé›‡ä¸»è´£ä»»ä¿é™©'),
        (r'ç½‘çº¦é…é€å‘˜', 'ç½‘çº¦é…é€å‘˜é›‡ä¸»è´£ä»»ä¿é™©'),
        (r'çŸ³æ²¹çŸ³åŒ–è¡Œä¸š[A-Z]?æ¬¾?', 'çŸ³æ²¹çŸ³åŒ–è¡Œä¸šé›‡ä¸»è´£ä»»ä¿é™©'),
        (r'é›†æˆç”µè·¯è¡Œä¸š', 'é›†æˆç”µè·¯è¡Œä¸šé›‡ä¸»è´£ä»»ä¿é™©'),
        (r'ç‰¹ç§è®¾å¤‡å®‰å…¨è´£ä»»', 'ç‰¹ç§è®¾å¤‡å®‰å…¨è´£ä»»ä¿é™©'),
        (r'æŠ¤ç†æœåŠ¡è´£ä»»', 'æŠ¤ç†æœåŠ¡è´£ä»»ä¿é™©'),
        (r'æ°‘å®¿ç»è¥è´£ä»»', 'æ°‘å®¿ç»è¥è´£ä»»ä¿é™©'),
        (r'ç‡ƒæ°”æ°”ç“¶å®‰å…¨è´£ä»»', 'ç‡ƒæ°”æ°”ç“¶å®‰å…¨è´£ä»»ä¿é™©'),
        (r'å®‰å…¨ç”Ÿäº§è´£ä»»', 'å®‰å…¨ç”Ÿäº§è´£ä»»ä¿é™©'),
        (r'é£Ÿå“å®‰å…¨è´£ä»»', 'é£Ÿå“å®‰å…¨è´£ä»»ä¿é™©'),
    ]
    for pat, ind in industry_patterns:
        if re.search(pat, name):
            industry = ind
            break

    # æå–æ¡æ¬¾ç®€ç§°
    clause_name = name.replace('è´¹ç‡æ–¹æ¡ˆ', '').strip()
    # å»æ‰è¡Œä¸šå‰ç¼€ï¼Œæå–é™„åŠ é™©åç§°
    m = re.search(r'é™„åŠ (.+?)(?:æ¡æ¬¾|ä¿é™©)?$', clause_name)
    if m:
        clause_name = 'é™„åŠ ' + m.group(1)
        if not clause_name.endswith('æ¡æ¬¾') and not clause_name.endswith('ä¿é™©'):
            clause_name = clause_name.rstrip('ï¼ˆï¼‰()')

    return {
        "clauseName": clause_name.strip(),
        "fullName": filename.replace('.docx', '').replace('.doc', ''),
        "industry": industry
    }


# ---------------------------------------------------------------------------
# ä¸»å¤„ç†
# ---------------------------------------------------------------------------
def _read_doc_file(filepath):
    """å°è¯•è¯»å– .doc æ–‡ä»¶ï¼Œè¿”å› (paragraphs, tables) æˆ– Noneã€‚"""
    import subprocess
    import shutil

    # å°è¯• antiword â†’ catdoc çš„é¡ºåº
    for cmd in ['antiword', 'catdoc']:
        if not shutil.which(cmd):
            continue
        try:
            result = subprocess.run(
                [cmd, filepath],
                capture_output=True, text=True, timeout=30
            )
            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split('\n')
                paragraphs = [
                    line.strip() for line in lines
                    if line.strip() and not is_noise(line.strip())
                ]
                return paragraphs, []
        except Exception:
            continue

    # å°è¯• textract (éœ€ pip install textract)
    try:
        import textract
        raw = textract.process(filepath).decode('utf-8', errors='ignore')
        lines = raw.strip().split('\n')
        paragraphs = [
            line.strip() for line in lines
            if line.strip() and not is_noise(line.strip())
        ]
        return paragraphs, []
    except Exception:
        pass

    return None


def process_file(filepath):
    """å¤„ç†å•ä¸ª docx/doc æ–‡ä»¶ï¼Œè¿”å›è´¹ç‡æ¡ç›®æˆ– Noneã€‚"""
    filename = os.path.basename(filepath)

    if not filename.endswith('.docx') and not filename.endswith('.doc'):
        return None

    # å¤„ç† .doc æ–‡ä»¶ï¼ˆé .docxï¼‰
    if filename.endswith('.doc') and not filename.endswith('.docx'):
        result = _read_doc_file(filepath)
        if result is None:
            print(f"  âš ï¸  .doc æ–‡ä»¶éœ€è¦ antiword/catdoc/textract: {filename}", file=sys.stderr)
            return None
        paragraphs, tables = result
        file_info = parse_filename(filename)
        rate_info = classify_and_extract(paragraphs, tables, filename)
        return {
            **file_info,
            **rate_info,
            "sourceFile": filename
        }

    try:
        doc = Document(filepath)
    except Exception as e:
        print(f"  âš ï¸  æ— æ³•æ‰“å¼€: {filename} - {e}", file=sys.stderr)
        return None

    paragraphs = clean_paragraphs(doc)
    tables = parse_tables(doc)

    # æ–‡ä»¶åè§£æ
    file_info = parse_filename(filename)

    # åˆ†ç±»å¹¶æå–
    rate_info = classify_and_extract(paragraphs, tables, filename)

    return {
        **file_info,
        **rate_info,
        "sourceFile": filename
    }


def process_directory(dir_path, verbose=False):
    """å¤„ç†ç›®å½•ä¸­æ‰€æœ‰è´¹ç‡æ–¹æ¡ˆ docx æ–‡ä»¶ã€‚"""
    if not os.path.isdir(dir_path):
        print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨ - {dir_path}", file=sys.stderr)
        sys.exit(1)

    # å¤„ç†è´¹ç‡æ–¹æ¡ˆæ–‡ä»¶ï¼ˆ.docx å’Œ .docï¼‰
    files = [
        f for f in sorted(os.listdir(dir_path))
        if 'è´¹ç‡æ–¹æ¡ˆ' in f and (f.endswith('.docx') or f.endswith('.doc'))
    ]

    print(f"ğŸ“‚ æ‰«æç›®å½•: {dir_path}")
    print(f"ğŸ“„ æ‰¾åˆ°è´¹ç‡æ–¹æ¡ˆæ–‡ä»¶: {len(files)} ä¸ª")

    entries = []
    stats = {}
    errors = 0

    for i, fname in enumerate(files, 1):
        fpath = os.path.join(dir_path, fname)
        if verbose:
            print(f"  [{i}/{len(files)}] {fname}")

        entry = process_file(fpath)
        if entry:
            rate_type = entry.get("rateType", "unknown")
            stats[rate_type] = stats.get(rate_type, 0) + 1
            entries.append(entry)
            if verbose:
                print(f"    â†’ {rate_type}")
        else:
            errors += 1

    print(f"\nâœ… å¤„ç†å®Œæˆ:")
    for rt in sorted(stats.keys()):
        print(f"   {rt:25s} {stats[rt]}")
    if errors:
        print(f"   {'errors':25s} {errors}")
    print(f"   {'æ€»è®¡':24s} {len(entries)}")

    return {
        "version": "2.1",
        "generatedAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "sourceDirectory": dir_path,
        "totalEntries": len(entries),
        "stats": stats,
        "entries": entries
    }


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser(
        description="ä»è´¹ç‡æ–¹æ¡ˆ docx æ–‡ä»¶æå–ç»“æ„åŒ– JSON æ•°æ®"
    )
    parser.add_argument(
        "directory",
        help="åŒ…å«è´¹ç‡æ–¹æ¡ˆ docx æ–‡ä»¶çš„ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "-o", "--output",
        default="rate_data.json",
        help="è¾“å‡º JSON æ–‡ä»¶è·¯å¾„ (é»˜è®¤: rate_data.json)"
    )
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯"
    )

    args = parser.parse_args()

    result = process_directory(args.directory, verbose=args.verbose)

    output_path = args.output
    if not os.path.isabs(output_path):
        output_path = os.path.join(os.getcwd(), output_path)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")


if __name__ == "__main__":
    main()
